# Information
- **Time:** 13:20 - 13:40
- **Attendees:** Bob Zhang (Supervisor), Huang Yanzhen, Mai Jiajun
# Discussion Summary

## 1. Frontend update
### 1.1 Adjusted the size üé®
The video of frontend is now bigger and more clear as Huang used the component of canvas, the face is more clear to be distinguished when applying face recognition.

### 1.2 Storage Backend ‚òÅ
Unlike the inference backend and the frontend, the storage backend is deployed in the cloud with Digital Ocean, on an Ubuntu Linux server. The deployment details could be found in this repository https://github.com/FYP-hyz-mjj-2024/posture-face-compare.git in the README file. It is too large so we didn't write them in this meeting notes.

The domain is https://www.youfocusyourwalk.top (This site has no web pages. It currently only serves as the server that handles data management requests.) The CORS policy is generous since the frontend is deployed on local.

To ensure safety, an Nginx reverse proxy is applied to forward HTTP requests to the correct port. (Nginx listens 80 but the FastAPI server works in 8081 and the database works in 5432). Certbot is used to auto certify the security of the domain mentioned above with SSL, providing HTTPS. The server is scripted to automatically renew the SSL certificate every 3:00 a.m. UTC+0 to keep the HTTPS connection valid.

## 2. Bug Fixes
### 2.1 Focal Loss Alpha
Alpha is the balancing factor in focal loss. 

$$
    L_{FL}(\mathbf{x},\mathbf{y})=-\sum_{i=1}^{N}\alpha_{i} \cdot y_{i}\cdot(1-\text{softmax}(\mathbf{x})_{i})^{\gamma}\cdot\log(\text{softmax}(\mathbf{x})_i)
$$

We fixed a bug where a single alpha in the original focal loss is used. It is suggested to use an alpha for the positive data and a corresponding 1-alpha for the negative data samples (according to the author of this paper https://arxiv.org/abs/1708.02002v2). The paper suggested to use the inverse frequency as the alpha, but since our data is too abundant (over 10,000), we used the negative sample's portion as the alpha for the positive samples, which is around 0.377.

## Next Meeting's Agenda
1. May try to learn the main knowledge of gaze estimation and schedule to apply the tech in our project to improve the performance.
2. 