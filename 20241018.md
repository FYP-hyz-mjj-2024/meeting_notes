# Information
- **Time:** 
- **Attendees:** Bob Zhang (Supervisor), Huang Yanzhen, Mai Jiajun

# Meeting Agenda (Week Oct. 7 - Oct. 11)
## 1. Refactoring
- Move `videoDemo` out from annotate image
- Performance Optimization
	- Comprehension `for` loops to boost performance
		- Use `[do_sth(item) for item in items]`, 
		  instead of `for item in items: do_sth(item)`
		- [Reference to this property](https://medium.com/@nirmalya.ghosh/13-ways-to-speedup-python-loops-e3ee56cd6b73)
		- Boosts up to around $2.5\times$ faster than regular ones.
		- Better for real-time application.
	- Use the `tiny` version of the model.
- Directly convert a video to a `.npy` file.
## 2. Record More Dataset
- Added a video for `WN-Wiggle` for better balancing the model.
- Recorded:
	- `WN-FoldArms`
	- `CR-Lift` $\times 2$
	- `CR-Hold`
	- `CR-Backpack`
## 3. Modification on MLP
### 3.1 About the new convolutional layers
- Added three convolutional layers (Just a try)
	- Input Dimension:
		- $9$, with scores removed.
	- Convolutional Layer Dimensions:
		- $9\rightarrow 16$
		- $16\rightarrow 32$
		- $32\rightarrow 64$
	- Fully connected layer Dimensions:
		- $64\rightarrow 100$
		- $100\rightarrow 100$
		- $100\rightarrow 100$
		- $100\rightarrow 2$
	- Output Dimension:
		- $2$
	- Aiming to potentially catch up the dependencies among features
		- Indeed there are dependencies among features by design.
### 3.2 Training Results

**Training Details**

| Item                  | Content            | Description       |
| --------------------- | ------------------ | ----------------- |
| Initial Leraning Rate | 0.0001             | Optimized by Adam |
| Optimizer             | Adam               |                   |
| Loss                  | Cross Entropy Loss |                   |
| Epoch                 | 500                |                   |
| Train/Test Ratio      | 0.65/0.35          |                   |

**Training Results**

| Training | Posture Estimation Model | Equipment (GPU) | Data Num       | Train Accuracy | Test Accuracy | Loss   |
| -------- | ------------------------ | --------------- | -------------- | -------------- | ------------- | ------ |
|          | RTMPose Medium           | RTX-4060 Laptop | 2907 +, 2537 - | 0.7504         | 0.7492        | 0.5539 |

**Train-Loss Graph**

<a href="https://sm.ms/image/GAEMUYhyCts97Pi" target="_blank"><img src="https://s2.loli.net/2024/10/11/GAEMUYhyCts97Pi.png" style="width:450px;" ></a>

**Training Console**

<a href="https://sm.ms/image/CtV96zjAkLaxR4H" target="_blank"><img src="https://s2.loli.net/2024/10/11/CtV96zjAkLaxR4H.png" style="width:400px;"></a>

## 4. Visual Inspection on Model Performance
### 4.1 How it looks
- It performs better on Mai, who is the "model" of the dataset
	- Potential overfitting
	- Improve dataset or re-consider model structure.
- It performs better without considering the scores of angles.
	- When angle scores are included, the model glitches.
	- We think it is due to the randomness of the score from MMPose models.
- It displays chirality:
	- My right hand can easily trigger. (Writer: Huang Yanzhen)
	- My left hand doesn't trigger at all.
	- Seems to overfit on my right hand.
### 4.2 What we think
- Training Data's Variety.
- Bad feature selection, or feature selection meets unstable model.
	- Model can't detect feature well?
---
# Meeting Agenda (Week Oct. 12 - Oct. 19)
## 1. Redesign target_list
- Using all 13 landmarks on upper body, and use combination to generate $C^3_{13}=286$ angles. 
- We also retry to use another $286$ scores to each angle, making the total number of features up to $572$ .
### 2. Adjustments on some parameters in CNN
- 3 independent convolutional layers were tuned with the number of input_channel and output_channel.
- The number of channels?: "gets more before getting fewer" or "gets fewer before getting more"?
- Brainstorming on what kind of activation function to use. ($\text{Relu, Leaky Relu, ELU}\dots$)
### 3. Dilemma of data collection
- Using - > Suspicious: whether to focus on both "Suspicious" and "Not_suspicious" or just collect the "Suspicious" data?
- How about apply the visual tools to collect data? (Movement Capture)
### 4. 