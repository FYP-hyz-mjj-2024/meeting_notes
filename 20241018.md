# Information
- **Time:** 
- **Attendees:** Bob Zhang (Supervisor), Huang Yanzhen, Mai Jiajun
- **Note:**
	- The Friday of week Oct. 7 - Oct. 11 was a public holiday. As we usually plan to meet on Fridays, the meeting is postponed. However, a report (which usually served as the meeting agenda) is written to put into discussion in this week.
	- Therefore, the meeting notes this week contains our work in two meetings.

# Work Report (Week Oct. 7 - Oct. 11)
## 1. Refactoring
- Move `videoDemo` out from annotate image
- Performance Optimization
	- Comprehension `for` loops to boost performance
		- Use `[do_sth(item) for item in items]`, 
		  instead of `for item in items: do_sth(item)`
		- [Reference to this property](https://medium.com/@nirmalya.ghosh/13-ways-to-speedup-python-loops-e3ee56cd6b73)
		- Boosts up to around $2.5\times$ faster than regular ones.
		- Better for real-time application.
	- Use the `tiny` version of the model.
- Directly convert a video to a `.npy` file.
## 2. Record More Dataset
- Added a video for `WN-Wiggle` for better balancing the model.
- Recorded:
	- `WN-FoldArms`
	- `CR-Lift` $\times 2$
	- `CR-Hold`
	- `CR-Backpack`
## 3. Modification on MLP
### 3.1 About the new convolutional layers
- Added three convolutional layers (Just a try)
	- Input Dimension:
		- $9$, with scores removed.
	- Convolutional Layer Dimensions:
		- $9\rightarrow 16$
		- $16\rightarrow 32$
		- $32\rightarrow 64$
	- Fully connected layer Dimensions:
		- $64\rightarrow 100$
		- $100\rightarrow 100$
		- $100\rightarrow 100$
		- $100\rightarrow 2$
	- Output Dimension:
		- $2$
	- Aiming to potentially catch up the dependencies among features
		- Indeed there are dependencies among features by design.
### 3.2 Training Results

**Training Details**

| Item                  | Content            | Description       |
| --------------------- | ------------------ | ----------------- |
| Initial Leraning Rate | 0.0001             | Optimized by Adam |
| Optimizer             | Adam               |                   |
| Loss                  | Cross Entropy Loss |                   |
| Epoch                 | 500                |                   |
| Train/Test Ratio      | 0.65/0.35          |                   |

**Training Results**

| Training | Posture Estimation Model | Equipment (GPU) | Data Num       | Train Accuracy | Test Accuracy | Loss   |
| -------- | ------------------------ | --------------- | -------------- | -------------- | ------------- | ------ |
|          | RTMPose Medium           | RTX-4060 Laptop | 2907 +, 2537 - | 0.7504         | 0.7492        | 0.5539 |

**Train-Loss Graph**

<a href="https://sm.ms/image/GAEMUYhyCts97Pi" target="_blank"><img src="https://s2.loli.net/2024/10/11/GAEMUYhyCts97Pi.png" style="width:450px;" ></a>

**Training Console**

<a href="https://sm.ms/image/CtV96zjAkLaxR4H" target="_blank"><img src="https://s2.loli.net/2024/10/11/CtV96zjAkLaxR4H.png" style="width:400px;"></a>

## 4. Visual Inspection on Model Performance
### 4.1 How it looks
- It performs better on Mai, who is the "model" of the dataset
	- Potential overfitting
	- Improve dataset or re-consider model structure.
- It performs better without considering the scores of angles.
	- When angle scores are included, the model glitches.
	- We think it is due to the randomness of the score from MMPose models.
- It displays chirality:
	- My right hand can easily trigger. (Writer: Huang Yanzhen)
	- My left hand doesn't trigger at all.
	- Seems to overfit on my right hand.
### 4.2 What we think
- Training Data's Variety.
- Bad feature selection, or feature selection meets unstable model.
	- Model can't detect feature well?
---
# Meeting Agenda (Week Oct. 12 - Oct. 19) Part. 1
## 1. Redesign `target_list`
Using all $13$ landmarks on upper body, and use combination to generate $C^3_{13}=286$ angles. 
- That is, we used every possible angle as our feature, and let the neuron network to select them.
Angle Score re-enters our vision ---- We also retry to use the scores to each angle. Considering we now have $286$ angles already, the total number of features rises up to $572$ .

## 2. Adjustments on some parameters in CNN
### 2.1 Convolutional Layers
Since the total number of features of each data sample goes from 9 to 572, the convolutional layers also needs to be adjusted to handle this change. The new structure of the network is given below.

<a href="https://sm.ms/image/VP6ib8zejpoMAXh" target="_blank">
<img src="https://s2.loli.net/2024/10/14/VP6ib8zejpoMAXh.png" style="width:400px">
</a>

There are still $3$ one-dimensional convolutional layers, but each layer's input-output size is re-designed to be gradually decreasing from $572$ to $64$, with each being:
- Layer 1: $572 \rightarrow 256$
- Layer 2: $256 \rightarrow 128$
- Layer 3: $128 \rightarrow 64$
We designed the convolutional network like this in attempt to gradually compress the dimension of the data, while also discovering local dependencies.
### 2.2 Activation Function
We recently discovered that, since we use $z$ - normalization that suppresses data into a range of $[-1, 1]$, using the classical $\text{ReLU}$ function may cause potential information loss, since it casts negative values into 0 in an equal manner.

Therefore, instead of $\text{ReLU}$, we use $\text{ELU}$ as our activation function. While being the same in the non-negative part as $\text{ReLU}$, it preserves information of negative inputs with function:
$$
\text{ELU}(x)=\begin{cases}x & x\geq 0 \\ 
\alpha\left(e^{x}-1\right) & x<0\end{cases}
$$
We also looked into other possible candidates for our activation function, including $\text{ReLU}$ and $\text{Leaky Relu}$.
$$
\text{Leaky Relu}(x)=\begin{cases}x & x\geq 0 \\ 
0.1x & x<0\end{cases}
$$
### 2.3 Training
**Hyper Parameters**

| Item                  | Content            | Description       |
| --------------------- | ------------------ | ----------------- |
| Initial Leraning Rate | $0.0001$           | Optimized by Adam |
| Optimizer             | Adam               |                   |
| Loss                  | Cross Entropy Loss |                   |
| Epoch                 | $500$              |                   |
| Train/Test Ratio      | $0.65/0.35$        |                   |

**Training Results**

| Posture Estimation Model | Equipment (GPU) | Data Num          | Train Accuracy | Test Accuracy | Loss     |
| ------------------------ | --------------- | ----------------- | -------------- | ------------- | -------- |
| RTMPose Medium           | RTX-4060 Laptop | $2907 +,$$2537 -$ | $0.9822$       | $0.9607$      | $0.3324$ |

**Train-Loss Graph**

<a href="https://sm.ms/image/ycfuaYANCv6wMG8" target="_blank">
<img src="https://s2.loli.net/2024/10/14/ycfuaYANCv6wMG8.png" style="width: 400px">
</a>

**Training Console**

<a href="https://sm.ms/image/KA4QN9BOR8Gvs72" target="_blank">
<img src="https://s2.loli.net/2024/10/14/KA4QN9BOR8Gvs72.png" style="width: 400px">
</a>

## 3. Issues & Ideas
This contains some ideas that's not (yet) been implemented.
### 3.1 Data Collection
- Turn `Using` into `Suspicious` since we plan to use multi-layer detection.
- Any trainable models, other than NN, that allow us to *only* collect the `Suspicious` data?
	- That is, to use **Elimination** method.
- Apply Movement capture technology in data collection?
### 3.2 Network Structure?
- The entire network should be gradually smaller/larger as it proceeds?
---
# Meeting Agenda (Week Oct. 12 - Oct. 19) Part. 2
## 1. Redesign `neural network`
We found that the amount of possible postures for "not using" is quit large!
- After brainstorming, we tried to build a new neural network named "Exclusive Network", which oughts to classify an input to one known class or "unknown" if it finds that the $\max\limits_{i\in1,2,\cdots,c}\hat{P}(\omega_i|\mathbf{input}) < threshold$ .
## 2. Accuracy, Precision, Recall and $F_1$ score
Accuracy is not the only criterion to judge whether a model trained is better or worse.
## 3. About the method on data collection
We had been collecting data by recording videos with different posturesã€‚
- but the workload is still too great, and manual recording of data requires a high degree of control over camera angles.
- how about using UE4 rebuild the posture animation and apply it on 2D capture as input.