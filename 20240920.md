# Information
- **Time:** 13:20 - 14:00
- **Attendees:** Bob Zhang (Supervisor), Mai Jiajun, Huang Yanzhen
# Discussion Summary
This week, we are only exploring data collection and model training using a Neural Network.
## 1. Data Collection
### 1.1 What we've got: Videos
Due to the lack of resources and resource varieties on the internet, we decided to use ourselves & people around us as the data source. We capture videos that surrounds the human model for a cycle, and crop each image frame out as a data source. We displayed the sample videos we have recorded in front of our supervisor.

Here lists the video file names we've shot for both labels:
- Not Using:
	- `2024_0919_1527_xyl_N_A.mp4`
- Using: 
	- `2024_0919_1517_xyl_U_A.mp4` (Horizontal Aspect Ratio)
	- `2024_0919_1523_xyl_U_A.mp4` (Vertical Aspect Ratio)
- Equipment:
	- DJI Osmos 6 Stabiliser 
- Human Posture Model
	- Xue Yulin (our friend)

### 1.2 Naming Paradigm
To better manage training data and trail its source, we proposed a naming paradigm to name videos. The paradigm is:
```
YYYYMMDD_hhmm_name_label_variants.mp4
```
- `YYYYMMDD`: Date of Capture.
- `hhmm`: Time of Capture.
- `name`: Chinese Pinyin abbreviation of the human model's name.
- `label`: The label of the batch data.
	- `U`: Using;
	- `N`: Not Using.
- `variants`: Ensuring data variety.
	- `L`: Left hand holding phone;
	- `R`: Right hand holding phone;
	- `B`: Both hands holding phone;
	- `A`: All of above had appeared in the video.

### 1.3 Ideas of improvements: Data Variety
Considering thatÂ capturing videos gives us the variety of perspectives, we could create more varieties in multiple variables. While capturing...
- angle of elbow
- left hand or right hand
- lift angle of face
  
## 2. Model Training
### 2.1 Model Training Information

| Item                  | Content            | Description       |
| --------------------- | ------------------ | ----------------- |
| Initial Leraning Rate | 0.001              | Optimized by Adam |
| Optimizer             | Adam               |                   |
| Loss                  | Cross Entropy Loss |                   |
| Epoch                 | 100                |                   |
| Train/Test Ratio      | 0.8/0.2            |                   |

### 2.2 Trains

| Training           | Posture Estimation Model | Equipment (GPU)         | Data Num       | Train Accuracy | Test Accuracy | Loss   |
| ------------------ | ------------------------ | ----------------------- | -------------- | -------------- | ------------- | ------ |
| Limited Training   | RTMPose Tiny             | MacBook Pro 2021 M1 MPS | 2000 +, 1000 - | 0.9636         | 0.9653        | 0.3557 |
| Unlimited Training | RTMPose Medium           | Nvidia RTX4060          | 4900+, 1662 -  | 0.9654         | 0.9640        | 0.3488 |

In the "Unlimited Training", we used all the image frames extracted from videos in both classes.

### 2.3 Results
We displayed the training results on the sample datasets, which is much more abundant than the previous 100-people-per-class one. We introduced the current training and testing accuracy.

These results are "one-shot" results, meaning that there would be a random factor due to the shuffle in the training data. 

| Training           | Graphs                                                  | Console                                                   |
| ------------------ | ------------------------------------------------------- | --------------------------------------------------------- |
| Limited Training   | ![[meetings/assets/20240920/train_limited_graph.jpg]]   | ![[meetings/assets/20240920/train_limited_console.jpg]]   |
| Unlimited Training | ![[meetings/assets/20240920/train_unlimited_graph.jpg]] | ![[meetings/assets/20240920/train_unlimited_console.png]] |

### 2.4 Ideas
We think that it is quite obvious that the size of the dataset plays a crucial role in the training results. We are planning continue shooting videos and add more varieties & noises into the dataset for better results.

Moreover, we are planning to train under a heavier model for better accuracy and run under a lighter model for better real-time performance.

## 3. Brain Storming
### 3.1 Is NN necessarily the best?
We have discussed about the efficiencies of other ML models (DT, SVR, ...) that could also perform vector classification. We displayed our experiments on the the old `posture` to experiment on the performances?
### 3.2 Multi-Level Detection
Multi-level detection. If the posture model thinks that a person is using the phone, then further detect their faces to re-ensure its decision. This is still in concept.
### 3.3 Extend to Multi-Class
Are Multi-class classification needed? Using+Not_using+Calling+...
Multi-Class Extension can enhance the product's extensibility.
### 3.4 Can we make MLP even better?
Enhancement of MLP(nn)? More layers? Better activation function?

# Agenda of Next Meeting
## 1. Things to Improve
- We have discovered that, if we keep every frame of the video, there would be duplicated data, on which the model tends to be over-dependent. Therefore, we discussed to save frame per second of every video. Moreover, we could also save room for videos of more people with more variety.
## 2. Expected Outcome
- Apply a semi-well trained nn to real-time camera and inspect its performance.