# Information
- **Time:** 13:20 - 
- **Attendees:** Bob Zhang (Supervisor), Huang Yanzhen, Mai Jiajun

# Meeting Agenda
## Brief Summary
The ExclusiveNet is not yet proven to be effective and we faced fatal problems while debugging.
- We found one tricky problem where we accidentally added a subtract sign which caused the training data to be in chaos.
- Does not perform closer to the minimum expectation. The "unknown" area is too hard to find.

We went back to the previous MLP and applied the knowledge from the CISC3024 course to adjust it. We are applying a similar approach as the VGGNet used in the field of image classification.

## 1. Cover More `Not Using` Data
We recorded some makeups to balance the training data and increase the variety of the data.
Recorded more tricky Not_Using class videos against to the lack exposed in last test of the MLP.

## 2. Correcting Convolutional Process
We realized that we have been using convolution in a wrong way previously.
- We used to be un-familiar with convolutional neural networks and we mistakenly reversed the channel number and the channel length.
	- While it should be $(\text{data num},\text{channel num}, \text{channel len})$
	- We instead used $(\text{data num}, \text{channel len}, \text{channel num})$
	- Therefore, we were actually convoluting $572$ of $1$-pixel channels, which is completely without usefulness.
- Figured out what disturbed us from improving the model's performance, we started to re-construct our neural network.

The reason why we need convolution is that we want to extract key bindings among multiple features. Therefore, we are trying to mimic the structure of VGGNet, using only $1\times3$ kernels in all the convolutional layers.
- For pre-processing, we fold our original $572$-length vector into a $2$ channelled $2\times 286$ matrix input to convolute the left & right corners with the middle part.
- Then, we immediately use the convolutional layers to convolute the original input into an $8$-channelled one with kernel size of $3$ and padding of $1$, without length reduction. More process is given below.

<a href="https://sm.ms/image/RvT4tsuwolnWY1I" target="_blank"><img src="https://s2.loli.net/2024/10/24/RvT4tsuwolnWY1I.png" ></a>

There are totally $2$ convolutional process. The first one convolutes the matrix from $2$ channels up to $16$ channels, Max-Pooling it to $16\times 143$ at the end, reducing the length by half. The second one convolutes the matrix from $16$ channels to $32$ channels, lastly Max-Pooling it to $32\times 71$ at the end, reducing the length by half. At last, we have a total number of $32*71=2272$ features to input into the fully-connected layers.

The fully-connected layers are simpler than before, containing only two layers. The first one reduces the input size from $2272$ to $256$, while the second one takes an input of $256$ and outputs the logits of size $2$, which is the one-of-k classification results.

Among all the layers, ELU (i.e., exponential ReLU) is used as the activation function.
## 3. Better evaluation Metrics
By calculating some standard metrics, we can observe the better script of the efficiency for each certain trained model.
### 3.1 Training Performance
Epoch: 650
LR: 1e-6

Hyper Parameters

| Posture Estimation Model | Equipment (GPU) | Data Num       | Epoch Num | LR   |
| ------------------------ | --------------- | -------------- | --------- | ---- |
| RTMPose Medium           | RTX-4060 Laptop | 3493 +, 3128 - | 650       | 1e-6 |

To overcome the potential lack of data variance, we purposely keep the model under-fitted to keep a higher variance with a lower bias. We also trained a better fitted model (Result at the end) and found the detection performance is much worse than the under-fitted one.
#### 3.1.1 Epoch-Loss Curves (EL)
<a href="https://sm.ms/image/apbWZP2eLxlduJw" target="_blank"><img src="https://s2.loli.net/2024/10/24/apbWZP2eLxlduJw.png" style="width:500px"></a>
We have received our **BEST EVER** model training performance ever, with respect to many aspects:
- **Fitting performance of the model.** The total loss of the model is satisfyingly low, meaning that the training data has been reasonably fitted.
- **Underfits at Convergence.** The epoch number and the learning rate is fine-tuned so that the model underfits at a convergence where the training and testing loss first meet.
- **Steady.** Third, due to our fine setting of learning rate, there isn't much fluctuation during the training process. The epoch-loss curves are all smooth.
#### 3.1.2 The Training Console

<a href="https://sm.ms/image/xyWkSgcRjXDE4zs" target="_blank"><img src="https://s2.loli.net/2024/10/24/xyWkSgcRjXDE4zs.png" style="width:300px" ></a>
#### 3.1.3 Over-Fitting Factor (OFF)
<a href="https://sm.ms/image/lc7UVxrdpty6hNB" target="_blank"><img src="https://s2.loli.net/2024/10/24/lc7UVxrdpty6hNB.png" style="width:500px"></a>

Besides epoch-loss curves, we also introduced a step-wise over-fitting factor. It is a measurement of how the model is fitting the data using the step-wise training and testing loss. The calculation of overfitting factor is as follows:
$$
\text{OFF}=tanh(\frac{\text{Testing Loss}-\text{Training Loss}}{\text{Testing Loss}})
$$
The closer this value is to $0$, the closer the under-fitting point we are getting. The smaller the value means that the training and testing loss is coming to convergence. However, if we want to train a well-fitted model on the training data, we would take another approach: 
$$\text{OFF}_i=\tanh{(\text{te}_{i-1}-\text{te}_i)}$$
Which is to find the approximation of the minimum point of the testing loss.

```functionplot
---
title: The tanh Function
xLabel: TEL-TRL
yLabel: Overfitting Factor
bounds: [-5, 5, -1, 1]
disableZoom: false
grid: true
---
f(x)=tanh(x)
```
By Observation,
- $\text{OFF}<0$, the model is "under fitting".
- $\text{OFF} > 0$, the model is "over fitting".
- $\text{OFF}=0$, the perfect spot we are looking for.

The model remained "under fitting".

### 3.2 Confusion Matrix (CM) & Precision-Recall Curve (PR)
#### 3.2.1 Confusion Matrix
<a href="https://sm.ms/image/YdahxwAFB49EcMH" target="_blank"><img src="https://s2.loli.net/2024/10/24/YdahxwAFB49EcMH.png" style="width:500px"></a>
Since we are only producing a binary classification, the confusion matrix is very intuitive in the model's classification performance. We retrieved all our data to perform classification. It is also easier to calculate all the useful evaluation metrics.
- Accuracy: $\text{ACC}=\frac{TP+TN}{TP+FP+TN+FN}=\frac{3193+2818}{3193+300+2818+310}=0.9709$
- Precision: $P=\frac{TP}{TP+FP}=\frac{3193}{3193+300}=0.9141$
- Recall: $R=\frac{TP}{TP+FN}=\frac{3193}{3193+310}=0.9115$
- $F_1$ Score: $F_1=\frac{2}{\frac{1}{P}+\frac{1}{R}}=0.9128$
#### 3.2.2 Precision-Recall Curve
<a href="https://sm.ms/image/QnJh3a65dP8skBH" target="_blank"><img src="https://s2.loli.net/2024/10/24/QnJh3a65dP8skBH.png" style="width:500px"></a>
We could also inspect this aspect by looking at the precision-recall curve. This is the curve plotted under different thresholds with respect to the scores in the one-of-k output. The closer the curves approaches the top-right corner, the better the model performs.
#### 3.2.3 ROC Curve
<a href="https://sm.ms/image/yXU9N3MFpWVwtCq" target="_blank"><img src="https://s2.loli.net/2024/10/24/yXU9N3MFpWVwtCq.png" style="width:500px"></a>

Similar to the PR curves, receive object characteristics curves, i.e., ROC curves, analyses the TPR and FPR under multiple thresholds. We could also reference the ROC curves to conclude that the model is performing in a great manner. The closer the curves approaches the top-left corner, the better the model performs.

## 3.4 In the end...
- üíº **Archive!** We have archived the model to preserve our work. 
	- This indicates that our first level of detection is reaching a local optimum.
	- Which means that our work in the first semester is nearly completed.
- üí™ **Enhance!** We will try to enhance the model even more.
	- Collect data that's even trickier to cover the edges.
	- Perform multiple trainings and attempt to find a better one than the archived.
- üë®‚Äçüè≠ **Field Test!** We would perform more field tests on the optimum model.
	- If the model performs well in practice, we will start our refining process: Clearing our code, enhancing the performance, possibly re-factoring, etc.
	- We will try to apply the second layer of detection ---- object detection as soon as possible. It is better to start earlier.

# 4. Deprecated Model
Below is the deprecated model that's well-fitted but performs bad.

| Posture Estimation Model | Equipment (GPU) | Data Num       | Epoch Num | LR   |
| ------------------------ | --------------- | -------------- | --------- | ---- |
| RTMPose Medium           | RTX-4060 Laptop | 3493 +, 3128 - | 950       | 5e-6 |
<a href="https://sm.ms/image/ZwB3Ajql8hLTebz" target="_blank"><img src="https://s2.loli.net/2024/10/25/ZwB3Ajql8hLTebz.png" alt="meetingnotes_1025_el.png" style="width:500px"></a>
<a href="https://sm.ms/image/NsOB5Qtwci8gmHW" target="_blank"><img src="https://s2.loli.net/2024/10/25/NsOB5Qtwci8gmHW.png" alt="meetingnotes_1025_cm.png" style="width:500px"></a>
<a href="https://sm.ms/image/H7mGNtsFaevREOd" target="_blank"><img src="https://s2.loli.net/2024/10/25/H7mGNtsFaevREOd.png" alt="meetingnotes_1025_off.png" style="width:500px"></a>
<a href="https://sm.ms/image/nz8XZHMP4iBfukt" target="_blank"><img src="https://s2.loli.net/2024/10/25/nz8XZHMP4iBfukt.png" alt="meetingnotes_1025_pr.png" style="width:500px"></a>
<a href="https://sm.ms/image/59LHdVNrg2QqBZK" target="_blank"><img src="https://s2.loli.net/2024/10/25/59LHdVNrg2QqBZK.png" alt="meetingnotes_1025_roc.png" style="width:500px"></a>
