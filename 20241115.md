# Information
- **Time:** 13:20 - 14:00
- **Attendees:** Bob Zhang (Supervisor), Huang Yanzhen, Mai Jiajun

# Discussion Summary
## 1. 3D Convolution
3D convolution is applied to make the model learn more efficiently. Starting from an angle value, at most 2 and normally 1 difference in the points could be found.

Ending the learning at the 270-th epoch. (Early-stopped)

Remark. We extract the first 13 landmarks detected by the RTMPose model as our raw features. These 13 landmarks include all the landmarks on the upper part of one's body.

We translate the raw features into a series of angles. This involves a combination problem. We first list all the possible corner points:
$$
cp=\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}, \ C_{13}^{1}=13
$$
Then, for each corner point, we exclude itself and select all the possible combinations from the remaining 12 candidates:
$$
\forall i\in[0,12] \ ep_{cp=i}, \ C_{12}^{2}=66 
$$
Lastly, we built a layered feature map to make the model learn more combined weights. According to our design, an angle is represented by `[(i, j), k]`, where `i` and `j` are the indexes (in range $[0,12]$) of the edge points and `k` is the index of the corner point. 

Fixing `k`, we could get a pyramid of all the combinations of the edge points without repetition, as we add a constraint requiring that `i` must be smaller than `j`. In each row of the matrix, `i` is fixed and `j` proceeds to grow until its maximum. `i` proceeds as row goes down. 

The largest row of the matrix has a maximum length of $11$, as the running `j` value in this row can't be the same as either its `i` value of the row or the `k` value of its pyramid. The height of the pyramid is also $11$ since `i` can't be the same as either the `i` value of the column or the `k` value of the pyramid. 

We put two pyramids from adjacent `k` values together, forming a matrix. The pyramid with an even `k` value is remained while its corresponding matrix with an odd `k` value is transposed to concatenation. After concatenation, we form a matrix of shape $12\times 11$. That is, each matrix corresponds to 2 adjacent `k` values.
<a href="https://sm.ms/image/PnqRjTMxKaZHOeB" target="_blank"><img src="https://s2.loli.net/2024/11/13/PnqRjTMxKaZHOeB.png" ></a>
From the above image, it could be inspected that `k=0` is paired with `k=1` and `k=2` is paired with `k=3`, and so on. As `k=12` has no remaining `k` values to be paired with, it is manually paired with the transposed pyramid of `k=0`. Except for some points near the edge of concatenation, all the points could find at most 1 difference in the edge points in its neighbours.

Putting multiple matrices together, it formed a cube.
<a href="https://sm.ms/image/corudp38WYM2vRV" target="_blank"><img src="https://s2.loli.net/2024/11/13/corudp38WYM2vRV.png" ></a>

For most data points, the data above and below has only 1 difference.

This design aims at putting angles with similar origins as close as possible for the model to convolute the relationships among them.

There are 2 channels, angles and scores, each being a cube. That is, the structure of the data sample of a single posture is designed to be 4-dimensional.

We use a convolution kernel of $3\times 5\times 5$ to convolute the 2-Channeled 3D cubes in the VGG-like network. We removed one MaxPool layer since it reduces the volume of one cube by the 3rd power to a unit, which costs too much information loss.

# 2. Training Performance
| Posture Estimation Model | Equipment (GPU) | Data Num       | Epoch Num            | LR   |
| ------------------------ | --------------- | -------------- | -------------------- | ---- |
| RTMPose Medium           | RTX-4060 Laptop | 4118 +, 3858 - | Early Stopped at 270 | 5e-6 |
We added an early-stopping mechanism to the model training process, using patience of 20. The model training stopped at the epoch of 270 while the maximum epoch is set to 650 previously. 650 was one optimum we discovered for the 1D convolutional network, meaning that this 3D convolution process made the model to learn 58% faster than before, reaching a similar loss.

|      | Loss | Batch Size | Normalized Loss          |
| ---- | ---- | ---------- | ------------------------ |
| 1101 | $~4$ | $32$       | $\frac{4}{32}=0.125$     |
| 1115 | $20$ | $128$      | $\frac{20}{128}=0.15625$ |

<a href="https://sm.ms/image/4FNKqJ3A5fyrvo8" target="_blank"><img src="https://s2.loli.net/2024/11/13/4FNKqJ3A5fyrvo8.png" style="width: 500px"></a>

<a href="https://sm.ms/image/vojqf8gaGdVhItM" target="_blank"><img src="https://s2.loli.net/2024/11/13/vojqf8gaGdVhItM.png" style="width: 500px"></a>
